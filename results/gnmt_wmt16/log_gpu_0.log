2019-05-08 14:58:17 - INFO - 0 - Saving results to: ../results/gnmt_wmt16
2019-05-08 14:58:17 - INFO - 0 - Run arguments: Namespace(batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, cupti=False, dataset_dir='/mnt/dataset/wmt_ende/', disable_eval=False, dist_url='tcp://localhost:23456', epochs=8, eval_batch_size=32, gpu_rank=0, grad_clip=5.0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, math='fp32', max_length_train=50, max_length_val=150, max_size=None, min_length_train=0, min_length_val=0, model_config="{'hidden_size': 1024,'num_layers': 4,                         'dropout': 0.2, 'share_embedding': True}", num_minibatches=20, optimization_config="{'optimizer': 'Adam', 'lr': 5e-4}", print_freq=10, profile=False, profile_dir='./profile', rank=0, results_dir='../results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, seed=1, smoothing=0.1, start_epoch=0, target_bleu=21.8, workers=0, world_size=1)
2019-05-08 14:58:17 - INFO - 0 - building vocabulary from /mnt/dataset/wmt_ende/vocab.bpe.32000
2019-05-08 14:58:17 - INFO - 0 - size of vocabulary: 36549
2019-05-08 14:58:17 - INFO - 0 - processing data from /mnt/dataset/wmt_ende/train.tok.clean.bpe.32000.en
